#!/usr/bin/env python3
"""
–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–±–µ–ª–æ–≤ –≤ –∑–Ω–∞–Ω–∏—è—Ö –±–µ–∑ LLM
–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ –ø–æ–∏—Å–∫ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
"""

import sys
import time
from pathlib import Path
from query_logger import QueryLogger

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º—É RAG-–±–æ—Ç—É
sys.path.append('./app')

try:
    from rag_bot import RAGConfig
    from langchain_huggingface import HuggingFaceEmbeddings
    from langchain_chroma import Chroma
except ImportError as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
    print("üí° –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:")
    print("pip install langchain-huggingface langchain-chroma")
    sys.exit(1)

class KnowledgeGapAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ø—Ä–æ–±–µ–ª–æ–≤ –≤ –∑–Ω–∞–Ω–∏—è—Ö (—Ç–æ–ª—å–∫–æ –ø–æ–∏—Å–∫, –±–µ–∑ LLM)"""
    
    def __init__(self, enable_logging: bool = True, log_format: str = "csv"):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞"""
        print("üîç –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –ø—Ä–æ–±–µ–ª–æ–≤ –≤ –∑–Ω–∞–Ω–∏—è—Ö...")
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        self.config = RAGConfig()
        
        # Embeddings –º–æ–¥–µ–ª—å
        self.embeddings = HuggingFaceEmbeddings(
            model_name=self.config.embedding_model,
            model_kwargs={'device': 'cpu'}
        )
        
        # –í–µ–∫—Ç–æ—Ä–Ω–∞—è –ë–î
        self.vector_db = Chroma(
            persist_directory=self.config.vector_db_path,
            embedding_function=self.embeddings
        )
        
        # –õ–æ–≥–≥–µ—Ä
        self.logger = QueryLogger(log_format=log_format) if enable_logging else None
        
        print("‚úÖ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
    
    def search_knowledge(self, query: str, k: int = 5) -> dict:
        """
        –ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π
        
        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            
        Returns:
            –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö –ø–æ–∏—Å–∫–∞
        """
        start_time = time.time()
        
        try:
            # –ü–æ–∏—Å–∫ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î
            results = self.vector_db.similarity_search_with_score(query, k=k)
            
            chunks_found = len(results)
            sources = []
            similarity_scores = []
            
            for doc, score in results:
                if hasattr(doc, 'metadata') and doc.metadata:
                    source = doc.metadata.get('source', 'unknown')
                    sources.append(source)
                
                # ChromaDB –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å—Ö–æ–∂–µ—Å—Ç—å
                similarity = 1.0 - score if score <= 1.0 else 0.0
                similarity_scores.append(round(similarity, 3))
            
            response_time_ms = int((time.time() - start_time) * 1000)
            
            # –°–æ–∑–¥–∞–µ–º mock-–æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —á–∞–Ω–∫–æ–≤
            if chunks_found > 0:
                mock_response = f"–ù–∞–π–¥–µ–Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –≤ {chunks_found} –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö: {', '.join(sources[:2])}..."
                if similarity_scores[0] < 0.3:  # –ù–∏–∑–∫–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å
                    mock_response = "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–∞–π–¥–µ–Ω–∞, –Ω–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Ç–æ—á–Ω–æ–π."
            else:
                mock_response = "–ò–∑–≤–∏–Ω–∏—Ç–µ, —è –Ω–µ –º–æ–≥—É –Ω–∞–π—Ç–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É."
            
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
            log_data = None
            if self.logger:
                log_data = self.logger.log_query(
                    query_text=query,
                    chunks_found=chunks_found,
                    response_text=mock_response,
                    sources=sources,
                    similarity_scores=similarity_scores,
                    response_time_ms=response_time_ms
                )
            
            return {
                'query': query,
                'chunks_found': chunks_found,
                'sources': sources,
                'similarity_scores': similarity_scores,
                'response': mock_response,
                'success': log_data['response_successful'] if log_data else chunks_found > 0,
                'response_time_ms': response_time_ms
            }
            
        except Exception as e:
            response_time_ms = int((time.time() - start_time) * 1000)
            
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–∫–∏
            if self.logger:
                self.logger.log_query(
                    query_text=query,
                    chunks_found=0,
                    response_text="",
                    response_time_ms=response_time_ms,
                    error_message=str(e)
                )
            
            return {
                'query': query,
                'chunks_found': 0,
                'sources': [],
                'similarity_scores': [],
                'response': f"–û—à–∏–±–∫–∞: {str(e)}",
                'success': False,
                'response_time_ms': response_time_ms,
                'error': str(e)
            }
    
    def test_knowledge_gaps(self):
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–±–µ–ª–æ–≤ –≤ –∑–Ω–∞–Ω–∏—è—Ö"""
        
        print("\nüß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ü–†–û–ë–ï–õ–û–í –í –ó–ù–ê–ù–ò–Ø–•")
        print("="*50)
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
        test_queries = [
            # –£–¥–∞–ª–µ–Ω–Ω—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏ (–¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø—Ä–æ–±–µ–ª–∞–º–∏)
            "–ß—Ç–æ —Ç–∞–∫–æ–µ Void Core?",
            "–†–∞—Å—Å–∫–∞–∂–∏ –æ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ Xarn Velgor",
            "–û–±—ä—è—Å–Ω–∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—é Synth Flux",
            
            # –°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏ (–¥–æ–ª–∂–Ω—ã –Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è)
            "–ö—Ç–æ —Ç–∞–∫–æ–π Arin Solara?",
            "–ß—Ç–æ —Ç–∞–∫–æ–µ Lumen Blade?", 
            "–†–∞—Å—Å–∫–∞–∂–∏ –æ –ø–ª–∞–Ω–µ—Ç–µ Elyndar",
            "–ö—Ç–æ —Ç–∞–∫–æ–π Kade Rhaul?",
            "–ß—Ç–æ —Ç–∞–∫–æ–µ Aeon Raptor?",
            
            # –û–±—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã
            "–ö–∞–∫–∏–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ —Å—É—â–µ—Å—Ç–≤—É—é—Ç?",
            "–ö—Ç–æ –≥–ª–∞–≤–Ω—ã–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–∏?"
        ]
        
        results = {
            'total_queries': len(test_queries),
            'successful': 0,
            'failed': 0,
            'gaps': [],
            'known': [],
            'details': []
        }
        
        print(f"üìã –í—Å–µ–≥–æ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤: {len(test_queries)}")
        print()
        
        for i, query in enumerate(test_queries, 1):
            print(f"üîç –¢–µ—Å—Ç {i}/{len(test_queries)}: {query}")
            
            result = self.search_knowledge(query)
            
            # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            chunks_found = result['chunks_found']
            success = result['success']
            
            if success:
                results['successful'] += 1
                results['known'].append(query)
                status = "‚úÖ –ù–ê–ô–î–ï–ù–û"
                details = f"—á–∞–Ω–∫–æ–≤: {chunks_found}, —Å—Ö–æ–∂–µ—Å—Ç—å: {result['similarity_scores'][0] if result['similarity_scores'] else 0:.3f}"
            else:
                results['failed'] += 1
                results['gaps'].append(query)
                status = "‚ùå –ü–†–û–ë–ï–õ"
                details = f"—á–∞–Ω–∫–æ–≤: {chunks_found}"
            
            print(f"   {status} ({details})")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–ª—è —É—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
            if success and result['sources']:
                print(f"   üìÇ –ò—Å—Ç–æ—á–Ω–∏–∫–∏: {', '.join(result['sources'][:2])}...")
            
            results['details'].append(result)
            print()
        
        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        success_rate = (results['successful'] / results['total_queries']) * 100
        
        print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø:")
        print(f"   –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {results['total_queries']}")
        print(f"   –£—Å–ø–µ—à–Ω—ã—Ö: {results['successful']}")
        print(f"   –ü—Ä–æ–±–µ–ª–æ–≤: {results['failed']}")
        print(f"   –ü—Ä–æ—Ü–µ–Ω—Ç –ø–æ–∫—Ä—ã—Ç–∏—è: {success_rate:.1f}%")
        print()
        
        # –í—ã—è–≤–ª–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã
        if results['gaps']:
            print("üö® –û–ë–ù–ê–†–£–ñ–ï–ù–ù–´–ï –ü–†–û–ë–ï–õ–´ –í –ó–ù–ê–ù–ò–Ø–•:")
            for i, gap in enumerate(results['gaps'], 1):
                print(f"   {i}. {gap}")
            print()
        
        # –ò–∑–≤–µ—Å—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        if results['known']:
            print("‚úÖ –ò–ó–í–ï–°–¢–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø:")
            for i, known in enumerate(results['known'], 1):
                print(f"   {i}. {known}")
            print()
        
        return results
    
    def get_analytics(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏"""
        return self.logger.get_analytics()

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    try:
        # –°–æ–∑–¥–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        analyzer = KnowledgeGapAnalyzer()
        
        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–±–µ–ª–æ–≤
        test_results = analyzer.test_knowledge_gaps()
        
        # –ê–Ω–∞–ª–∏—Ç–∏–∫–∞
        print("üìà –ê–ù–ê–õ–ò–¢–ò–ö–ê –õ–û–ì–û–í:")
        analytics = analyzer.get_analytics()
        
        for key, value in analytics.items():
            if key != 'recent_failed_queries':
                print(f"   {key}: {value}")
        
        # –ù–µ–¥–∞–≤–Ω–∏–µ –Ω–µ—É—Å–ø–µ—à–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
        if analytics.get('recent_failed_queries'):
            print("\nüö® –ù–ï–£–°–ü–ï–®–ù–´–ï –ó–ê–ü–†–û–°–´ (–≤—ã—è–≤–ª—è—é—Ç –ø—Ä–æ–±–µ–ª—ã):")
            for failed in analytics['recent_failed_queries']:
                print(f"   - {failed['query']} ({failed['timestamp'][:19]})")
        
        print("\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω! –õ–æ–≥–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ logs/query_logs/")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
