# Исследование моделей и инфраструктуры для RAG-бота QuantumForge

## Анализ задачи

**Заказчик**: ML Tech Lead QuantumForge Software  
**Пользователи**: Разработчики, саппорт, менеджеры, новые сотрудники  
**Масштаб**: ~18,000 Markdown + ~3,000 Confluence + ~250 PDF  
**Ключевые требования**: Конфиденциальность, SOC 2 compliance

## 1. Сравнение LLM-моделей

| Критерий | Локальные (Hugging Face) | Облачные (OpenAI/YandexGPT) |
|----------|--------------------------|------------------------------|
| **Качество ответов** | Llama 2 70B - хорошо, но уступает GPT-4 | GPT-4 - отличное качество |
| **Скорость работы** | 2-5 сек (зависит от железа) | 1-3 сек (API) |
| **Стоимость** | €8k сервер + €2k/мес содержание | €0 + €300-500/мес токены |
| **Развертывание** | Сложно, нужна ML экспертиза | Просто, готовое API |

**Рекомендация**: Для MVP - YandexGPT (быстрый старт), затем переход на локальную модель.

## 2. Сравнение моделей эмбеддингов

| Критерий | Локальные (Sentence-Transformers) | Облачные (OpenAI) |
|----------|-----------------------------------|-------------------|
| **Скорость индексации** | 15-20 мин для 21k docs | 5-10 мин |
| **Качество поиска** | all-mpnet-base-v2 - отличное | text-embedding-3 - отличное+ |
| **Стоимость** | €0 после setup | €1060 индексация + €200/мес |
| **Конфиденциальность** | ✅ Данные остаются внутри | ❌ Данные уходят в облако |

**Рекомендация**: Локальные эмбеддинги (all-mpnet-base-v2) из-за требований конфиденциальности.

## 3. Сравнение векторных БД

| Критерий | FAISS | ChromaDB |
|----------|-------|----------|
| **Скорость поиска** | <10ms (сверхбыстро) | 20-50ms (быстро) |
| **Скорость индексации** | 2-3 мин | 5-7 мин |
| **Сложность внедрения** | Низкая (pip install) | Очень низкая |
| **Метаданные** | Нет встроенной поддержки | ✅ Встроенная фильтрация |
| **Персистентность** | Требует внешнее решение | ✅ Автоматическое сохранение |
| **Интеграция с LangChain** | Базовая | ✅ Отличная |

**Рекомендация**: ChromaDB для простоты разработки и поддержки метаданных.

## 4. Конфигурация сервера

**Рекомендуемая конфигурация**:
- **CPU**: 16-32 ядра
- **RAM**: 64-128GB
- **GPU**: RTX 4090 (24GB VRAM) или Tesla T4
- **Storage**: 1TB NVMe SSD
- **Стоимость**: €5,000-8,000

## Итоговые рекомендации

### Вариант 1: Максимальная безопасность
- **LLM**: Llama 2 70B (локально)
- **Эмбеддинги**: all-mpnet-base-v2 (локально)
- **Векторная БД**: FAISS
- **Стоимость**: €15k + €2k/мес
- **Плюсы**: Полная конфиденциальность
- **Минусы**: Долгое внедрение, высокие затраты

### Вариант 2: Гибридный
- **LLM**: YandexGPT Pro → Llama 2 (поэтапно)
- **Эмбеддинги**: all-mpnet-base-v2 (локально)
- **Векторная БД**: ChromaDB
- **Стоимость**: €8k + €400/мес
- **Плюсы**: Быстрый старт, баланс безопасности/качества
- **Минусы**: Временная зависимость от облака

### Вариант 3: Облачный
- **LLM**: OpenAI GPT-4
- **Эмбеддинги**: OpenAI embeddings
- **Векторная БД**: Pinecone
- **Стоимость**: €0 + €800/мес
- **Плюсы**: Быстрое внедрение, лучшее качество
- **Минусы**: Проблемы с конфиденциальностью

## Финальная рекомендация

**Выбираю Вариант 2 (Гибридный)** по причинам:

1. **Конфиденциальность эмбеддингов**: Документы обрабатываются локально
2. **Быстрый MVP**: YandexGPT позволяет запуститься за 2-4 недели
3. **Путь миграции**: Четкий план перехода на полностью локальное решение
4. **ChromaDB**: Идеальный баланс простоты и функциональности для команды